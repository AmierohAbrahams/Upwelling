---
title: "Exploring_data"
author: "Amieroh Abrahams"
date: "16 May 2019"
output: html_document
---

# Some questions:
  # What is the climatological baseline
  # Calculate upwelling for all the years and then it a linear regression to find a trend
  # Spacially going to define upwelling
  # Run this on each pixel individually 
  # How will I combine the results for each EBUS to quntify the changes in upwelling
  
Climatological baseline varies per dataset. Climatological baseline for:
  OISST: 1982-01-01", "2011-12-31
  CMC:
  G1SST:
  
Uwpelling: Spatially defined as all the SST's falling within the 30th percentile range, lasting for a minimum of 2 days and a maximum of 3 days. 

# Loading packages

```{r}
csv.dir <- "/home/amieroh/Documents/spatial/data/csv"
```

# Adding column names
```{r}
BC <- read_csv("/home/amieroh/Documents/spatial/data/csv/BC-avhrr-only-v2.Document-Document.csv", col_names = c("lon", "lat", "temp", "t"))
CalC <- read_csv("/home/amieroh/Documents/spatial/data/csv/CalC-avhrr-only-v2.Document-Document.csv", col_names = c("lon", "lat", "temp", "t"))
CC <- read_csv("/home/amieroh/Documents/spatial/data/csv/CC-avhrr-only-v2.Document-Document.csv", col_names = c("lon", "lat", "temp", "t"))
# HC <- read_csv("/home/amieroh/Documents/spatial/data/csv/HC-avhrr-only-v2.Document-Document.csv", col_names = c("lon", "lat", "temp", "t"))
HC <- fread(paste0(csv.dCalCir, "/HC-avhrr-only-v2.Document-Document.csv"))
```

# Monthly data from daily data

```{r}
library(doMC); doMC::registerDoMC(cores = 4) # multi-core
require(mgcv)
library(data.table)
library(readr)
library(dplyr)
library(plyr)
library(lubridate)
library(tidyverse)


# functions.R
# a new date class
setClass('myDate')
setAs("character", "myDate", function(from) as.Date(fastPOSIXct(from, tz = NULL)))

# a fast date function
fastDate <- function(x, tz = NULL) {
  as.Date(fastPOSIXct(x, tz = tz))
}

monthly <- function(dailyData) {
  monthlyData <- dailyData %>%
    plyr::mutate(t = fastDate(t)) %>%
    dplyr::mutate(month = floor_date(t, unit = "month")) %>%
    dplyr::group_by(lon, lat, month) %>%
    dplyr::summarise(temp = mean(temp, na.rm = TRUE)) %>%
    dplyr::mutate(year = year(month)) %>%
    dplyr::group_by(lon, lat) %>%
    dplyr::mutate(num = seq(1:length(temp))) %>%
    dplyr::ungroup()
  return(monthlyData)
}

BC_monthly <- monthly(BC)
CalC_monthly <- monthly(CalC)
CC_monthly <- monthly(CC)
HC_monthly <- monthly(HC)

#inDir <- "/home/amieroh/Documents/Masters_2019/Upwelling/global_EBUS/data"
outDir <- "/home/amieroh/Documents/Masters_2019/Upwelling/global_EBUS/data"
# fwrite(BC_monthly,
#        paste0(outDir, "/BC_monthly",
#               format(as.Date(BC_monthly$month, format = "%Y%m%d"), "%Y%m%d")[1], "-",
#               format(as.Date(BC_monthly$month, format = "%Y%m%d"), "%Y%m%d")[nrow(BC_monthly)], ".csv"))
# 
# fwrite(CalC_monthly,
#        paste0(outDir, "/BC_monthly",
#               format(as.Date(BC_monthly$month, format = "%Y%m%d"), "%Y%m%d")[1], "-", 
#               format(as.Date(BC_monthly$month, format = "%Y%m%d"), "%Y%m%d")[nrow(BC_monthly)], ".csv"))

# Calculating the climatology
ts2clm.grid <- function(data) {
  out <- ts2clm(data, x = t, y = temp,
                climatologyPeriod = c("1982-01-01", "2011-12-31"),
                robust = FALSE, maxPadLength = 3, windowHalfWidth = 1,
                pctile = 30, smoothPercentile = TRUE,
                smoothPercentileWidth = 31, clmOnly = FALSE)
  return(out)
}

BC_clim <- ddply(BC, .(lon, lat), ts2clm.grid,
                 .parallel = TRUE, .progress = "text")

CalC_clim <- ddply(CalC, .(lon, lat), ts2clm.grid,
                 .parallel = TRUE, .progress = "text")

CC_clim <- ddply(CC, .(lon, lat), ts2clm.grid,
                 .parallel = TRUE, .progress = "text")

HC <- ddply(HC, .(lon, lat), ts2clm.grid,
                 .parallel = TRUE, .progress = "text")
```

# Seasonal climatology

```{r}
# a function to create monthly data from daily data
dailyseason <- function(dailyData) {
  seasonal <- dailyData %>%
    dplyr::mutate(t = month(t)) %>%
    dplyr::filter(t %in% c(12, 1, 2, 6, 7, 8)) %>%
    dplyr::mutate(t = dplyr::recode_factor(t, `12` = "DecJanFeb", `1` = "DecJanFeb", `2` = "DecJanFeb",
                                           `6` = "JuneJulyAug", `7` = "JuneJulyAug", `8` = "JuneJulyAug")) %>%
    dplyr::group_by(lon, lat, t) %>%
    dplyr::summarise(temp = mean(temp, na.rm = TRUE)) %>%
    dplyr::ungroup()
  return(seasonal)
}


BC_seas <- dailyseason(BC)
CalC_seas <- dailyseason(CalC)

# Plot seasonal climatologies
BC_fig1 <- ggplot(BC_seas, aes(x = lon, y = lat)) +
  facet_wrap(~ t) +
  geom_raster(aes(fill = temp), interpolate = FALSE)

CalC_fig1 <- ggplot(CalC_seas, aes(x = lon, y = lat)) +
  facet_wrap(~ t) +
  geom_raster(aes(fill = temp), interpolate = FALSE)
```

# Using the detect event function to detect when upwelling events occured. 

```{r}
OISST_detect2 <- function(dat) {
  require(heatwaveR)
  out <- heatwaveR::detect_event(dat)
  event <- out$event
  return(event)
}

setClass('myDate')
setAs(from = "character", to = "myDate", def = function(from) as.Date(fastPOSIXct(from, tz = NULL)))

BC.ev <- ddply(BC_clim, .(lon, lat), OISST_detect2, .parallel = TRUE, .progress = "text")
CalC.ev <- ddply(CalC_clim, .(lon, lat), OISST_detect2, .parallel = TRUE, .progress = "text")
HC.ev <- ddply(CalC_clim, .(lon, lat), OISST_detect2, .parallel = TRUE, .progress = "text")
CC.ev <- ddply(CalC_clim, .(lon, lat), OISST_detect2, .parallel = TRUE, .progress = "text")

# Here I determine the number of events per annum
mean_intensity <- function(events) {
  freq <- events %>%
    dplyr::mutate(year = year(date_start)) %>%
    dplyr::select(-date_start, -date_end, -date_peak) %>%
    dplyr::group_by(lon, lat, year) %>%
    dplyr::summarise(y = mean(intensity_mean)) %>%
    dplyr::ungroup() %>%
    as.tibble()
}

# Annual mean intensity
BC_annual <- mean_intensity(BC.ev)
CalC_annual <- mean_intensity(CalC.ev)
HC_annual <- mean_intensity(HC.ev)
CC_annual <- mean_intensity(CC.ev)

# linear function

linFun <- function(annualEvent, poissan = FALSE) {
  if (poissan) {
    mod <- glm(y ~ year, family = poisson(link = "log"), data = annualEvent)
  }
  else {
    mod <- lm(y ~ year, data = annualEvent)
  }
  trend <- data.frame(slope = summary(mod)$coefficients[2,1] * 10, pval = summary(mod)$coefficients[2,4])
  trend$pbracket <- cut(trend$pval, breaks = c(0, 0.001, 0.01, 0.05, 1))
  return(trend)
}
BC_annual_int <- ddply(BC_annual, .(lon, lat), linFun, poissan = FALSE, .parallel = TRUE)

# Maximum intensity trend
# Calculte the number of events per annum
max_intensity <- function(events) {
  freq <- events %>%
    dplyr::mutate(year = year(date_start)) %>%
    dplyr::select(-date_start, -date_end, -date_peak) %>%
    dplyr::group_by(lon, lat, year) %>%
    dplyr::summarise(y = mean(intensity_max)) %>%
    dplyr::ungroup() %>%
    as.tibble()
}

# Do the annual MaxInts
BC_annual_max <- max_intensity(BC.ev)
BC_annualmaxtrend <- ddply(BC_annual_max, .(lon, lat), linFun, poissan = FALSE, .parallel = TRUE)

# The duration of an upwelling event
Duration <- function(events) {
  dur <- events %>%
    dplyr::group_by(lon, lat) %>%
    dplyr::summarise(y = mean(duration, na.rm = TRUE)) %>%
    as.tibble()
}

BC_Duration <- Duration(BC.ev)
```

# Creating the shores for the various EBUS

```{r}

bbox <- data.frame(CC = c(25, 35, -20, -5), # Canary Current
                   row.names = c("latmin", "latmax", "lonmin", "lonmax"))

shoreDir <- "/home/amieroh/Documents/spatial/data/csv/EBUS/shorelines"
gshhsDir <- "/home/amieroh/Documents/Data/Datasets/gshhg-bin-2.3.7"

# create shorelines
makeShore <- function(shoreDir, gshhsDir, region) {
  require(ggplot2)
  require(rgeos)
  require(maptools) # maptools must be loaded after rgeos
  lims <- bbox[, region]
  lats <- c(lims[1], lims[2])
  lons <- c(lims[3], lims[4])
  shore <- fortify(getRgshhsMap(paste0(gshhsDir, "/gshhs_f.b"),
                                xlim = lons, ylim = lats, level = 1, no.clip = FALSE, checkPolygons = TRUE))
  save(shore, file = paste0(shoreDir, "/", region, "-shore.Rdata"))
}

makeShore(shoreDir, gshhsDir, "BC")
makeShore(shoreDir, gshhsDir, "CC")
makeShore(shoreDir, gshhsDir, "CalC")
makeShore(shoreDir, gshhsDir, "HC")

lats <- c(bbox["latmin", "GS"], bbox["latmax", "GS"])
lons <- c(bbox["lonmin", "GS"], bbox["lonmax", "GS"])
shore <- Rgshhs(paste0(gshhsDir, "/gshhs_f.b"), ## run Rgshhs directly; returns list
                xlim = lons, ylim = lats, level = 1, no.clip = FALSE, checkPolygons = TRUE)
shore <- fortify(shore$SP)
save(shore, file = paste0(shoreDir, "/", "GS", "-shore.Rdata"))
remove(shore)

# create the basemap
baseMap <- function(shoreDir, shoreFile) {
  load(paste0(shoreDir, "/", shoreFile))
  region <- sapply(str_extract_all(shoreFile, "\\b[A-Z]+\\b"), paste, collapse = ' ')
  coords <- bbox[, region]
  ggplot(shore, aes(x = lon, y = lat)) +
    geom_polygon(aes(x = long, y = lat, group = group),
                 fill = "#929292", colour = "black", size = 0.1, show.legend = FALSE) +
    xlab("Longitude (°E)") +
    ylab("Latitude (°S)") +
    coord_fixed(ratio = 1,
                xlim = c(coords[3], coords[4]),
                ylim = c(coords[1], coords[2]), expand = FALSE) +
    theme_bw()
  ggsave(paste0(shoreDir, "/", region, "-shore.pdf"), width = 8, height = 8)
}

# Plotting the shoresliens
baseMap(shoreDir, "BC-shore.Rdata")
baseMap(shoreDir, "CC-shore.Rdata")
baseMap(shoreDir, "CalC-shore.Rdata")
baseMap(shoreDir, "HC-shore.Rdata")
```



